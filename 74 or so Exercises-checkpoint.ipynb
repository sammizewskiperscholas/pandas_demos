{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc4bd4f0",
   "metadata": {},
   "source": [
    "1) Demonstrate how to import Pandas and check the version of the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3bc97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc4f4a",
   "metadata": {},
   "source": [
    "2) Transform this list, numpy array, and dictionary into a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b30b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     0\n",
      "b     1\n",
      "c     2\n",
      "e     3\n",
      "d     4\n",
      "f     5\n",
      "g     6\n",
      "h     7\n",
      "i     8\n",
      "j     9\n",
      "k    10\n",
      "l    11\n",
      "m    12\n",
      "n    13\n",
      "o    14\n",
      "p    15\n",
      "q    16\n",
      "r    17\n",
      "s    18\n",
      "t    19\n",
      "u    20\n",
      "v    21\n",
      "w    22\n",
      "x    23\n",
      "y    24\n",
      "z    25\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "series = pd.Series(mydict)\n",
    "\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17155a8",
   "metadata": {},
   "source": [
    "3) Convert the index of your previous series into a column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0f1395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index_name  values\n",
      "0           a       0\n",
      "1           b       1\n",
      "2           c       2\n",
      "3           e       3\n",
      "4           d       4\n",
      "5           f       5\n",
      "6           g       6\n",
      "7           h       7\n",
      "8           i       8\n",
      "9           j       9\n",
      "10          k      10\n",
      "11          l      11\n",
      "12          m      12\n",
      "13          n      13\n",
      "14          o      14\n",
      "15          p      15\n",
      "16          q      16\n",
      "17          r      17\n",
      "18          s      18\n",
      "19          t      19\n",
      "20          u      20\n",
      "21          v      21\n",
      "22          w      22\n",
      "23          x      23\n",
      "24          y      24\n",
      "25          z      25\n"
     ]
    }
   ],
   "source": [
    "mydf = series.reset_index()\n",
    "mydf.columns = ['index_name','values']\n",
    "print(mydf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f625f24",
   "metadata": {},
   "source": [
    "4) Combine the series below into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d268747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ser1  ser2\n",
      "0     a     0\n",
      "1     b     1\n",
      "2     c     2\n",
      "3     e     3\n",
      "4     d     4\n",
      "5     f     5\n",
      "6     g     6\n",
      "7     h     7\n",
      "8     i     8\n",
      "9     j     9\n",
      "10    k    10\n",
      "11    l    11\n",
      "12    m    12\n",
      "13    n    13\n",
      "14    o    14\n",
      "15    p    15\n",
      "16    q    16\n",
      "17    r    17\n",
      "18    s    18\n",
      "19    t    19\n",
      "20    u    20\n",
      "21    v    21\n",
      "22    w    22\n",
      "23    x    23\n",
      "24    y    24\n",
      "25    z    25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))\n",
    "\n",
    "df = pd.DataFrame({'ser1': ser1, 'ser2': ser2})\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd8618",
   "metadata": {},
   "source": [
    "5) Give the series below a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b18f9c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphabets\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'),name='alphabets')\n",
    "print(ser.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8d244",
   "metadata": {},
   "source": [
    "6) Find the elements in the first series (ser1) not in the second series (ser2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1276978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "#diff_elements = ser1[~ser1.isin(ser2)]\n",
    "#print(diff_elements)\n",
    "\n",
    "diff_elements = ser1[ser1.isin(ser2) == False]\n",
    "print(diff_elements)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3393a3",
   "metadata": {},
   "source": [
    "Find the elements in both series that are not in common (remove them if they exist in both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28768232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "diff_elements = ser1[ser1.isin(ser2) | ser2.isin(ser1)]\n",
    "print(diff_elements)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c40fa",
   "metadata": {},
   "source": [
    "8) Find the minimum, max, 25th percentile, and 75th percentile in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a1a3ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum:  0.15562039184778165\n",
      "Maximum:  19.676026945095522\n",
      "25th Percentile:  5.964487583218493\n",
      "75th Percentile:  13.054840185961599\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ser = pd.Series(np.random.normal(10, 5, 25))\n",
    "\n",
    "minimum = np.min(ser)\n",
    "maximum = np.max(ser)\n",
    "percentile_25 = np.percentile(ser,25)\n",
    "percentile_75 = np.percentile(ser,75)\n",
    "\n",
    "print(\"Minimum: \", minimum)\n",
    "print(\"Maximum: \", maximum)\n",
    "print(\"25th Percentile: \", percentile_25)\n",
    "print(\"75th Percentile: \", percentile_75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f067a1c9",
   "metadata": {},
   "source": [
    "9) Obtain the count of each unique item in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16a2880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h    6\n",
      "g    5\n",
      "a    4\n",
      "e    4\n",
      "f    3\n",
      "b    3\n",
      "c    3\n",
      "d    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n",
    "\n",
    "value_counts = ser.value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae324d",
   "metadata": {},
   "source": [
    "10) Keep the two most frequent items in the series and change all items that are not those two into \"Other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e86f2a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         2\n",
      "1         1\n",
      "2         1\n",
      "3         1\n",
      "4         2\n",
      "5         2\n",
      "6         2\n",
      "7         1\n",
      "8         1\n",
      "9     Other\n",
      "10    Other\n",
      "11    Other\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "\n",
    "# Find the two most frequent items in the series\n",
    "top_two = ser.value_counts().head(2).index.tolist()\n",
    "\n",
    "# Use the apply function to replace all other items in the series with \"Other\"\n",
    "ser = ser.apply(lambda x: x if x in top_two else 'Other')\n",
    "print(ser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffe101",
   "metadata": {},
   "source": [
    "11) Bin the series below into 10 equal deciles and replace the values with the bin name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "979b3d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      bin 8\n",
      "1      bin 4\n",
      "2      bin 4\n",
      "3      bin 8\n",
      "4      bin 7\n",
      "5      bin 1\n",
      "6      bin 1\n",
      "7     bin 10\n",
      "8      bin 9\n",
      "9      bin 4\n",
      "10     bin 3\n",
      "11     bin 3\n",
      "12     bin 1\n",
      "13    bin 10\n",
      "14     bin 5\n",
      "15     bin 5\n",
      "16     bin 8\n",
      "17     bin 1\n",
      "18    bin 10\n",
      "19     bin 1\n",
      "dtype: category\n",
      "Categories (10, object): ['bin 1' < 'bin 2' < 'bin 3' < 'bin 4' ... 'bin 7' < 'bin 8' < 'bin 9' < 'bin 10']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ser = pd.Series(np.random.random(20))\n",
    "\n",
    "# Bin the series into 10 equal deciles\n",
    "ser_binned = pd.cut(ser, bins=10, labels=range(1, 11))\n",
    "\n",
    "# Use the apply function to replace the values with the bin name\n",
    "ser_binned = ser_binned.apply(lambda x: f'bin {x}')\n",
    "\n",
    "print(ser_binned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0317e180",
   "metadata": {},
   "source": [
    "12) Reshape the series ser into a dataframe with 7 rows and 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17a3513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4\n",
      "0  6  9  6  1  4\n",
      "1  5  1  2  9  9\n",
      "2  8  1  4  7  6\n",
      "3  4  4  2  3  6\n",
      "4  6  9  5  1  3\n",
      "5  8  5  2  1  4\n",
      "6  4  8  7  3  8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "\n",
    "# reshape the series into a 7x5 array then convert the array to a dataframe\n",
    "\n",
    "df = pd.DataFrame(ser.values.reshape(7,5))\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab67cad",
   "metadata": {},
   "source": [
    "13) Find the positions of numbers that are multiples of 3 from ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ae884a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 3, 4], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "\n",
    "# Find the remainder of each element divided by 3\n",
    "remainders = np.mod(ser, 3)\n",
    "\n",
    "# Find the positions of the elements that have a remainder of 0\n",
    "positions = np.where(remainders == 0)\n",
    "\n",
    "print(positions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72923f7d",
   "metadata": {},
   "source": [
    "14) From ser, extract the items at positions in list pos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42338aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     a\n",
      "4     e\n",
      "8     i\n",
      "14    o\n",
      "20    u\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]\n",
    "\n",
    "# extract the items at the positions in the list pos\n",
    "extracted_items = ser.iloc[pos]\n",
    "\n",
    "print(extracted_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f26f9",
   "metadata": {},
   "source": [
    "15) Stack ser1 and ser2 vertically and horizontally (to form a dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dfea534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\n",
      "0  0\n",
      "1  1\n",
      "2  2\n",
      "3  3\n",
      "4  4\n",
      "0  a\n",
      "1  b\n",
      "2  c\n",
      "3  d\n",
      "4  e\n",
      "   0  1\n",
      "0  0  a\n",
      "1  1  b\n",
      "2  2  c\n",
      "3  3  d\n",
      "4  4  e\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "\n",
    "df_vertical = pd.concat([ser1, ser2], axis=0)\n",
    "df_vertical = pd.DataFrame(df_vertical)\n",
    "print(df_vertical)\n",
    "\n",
    "\n",
    "df_horizontal = pd.concat([ser1, ser2], axis=1)\n",
    "df_horizontal = pd.DataFrame(df_horizontal)\n",
    "print(df_horizontal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724cb0bd",
   "metadata": {},
   "source": [
    "16) Get the positions of items of ser2 in ser1 as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da51891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])\n",
    "\n",
    "# get the indexer\n",
    "indexer = ser1.index.get_indexer(ser2.index)\n",
    "\n",
    "# get the positions\n",
    "positions = [i for i in indexer if i >= 0]\n",
    "print(positions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4847b4",
   "metadata": {},
   "source": [
    "17) Compute the mean squared error of truth and pred series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df7ff599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4375552561148063\n"
     ]
    }
   ],
   "source": [
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)\n",
    "\n",
    "mse = ((truth - pred)**2).mean()\n",
    "print(mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf6f79",
   "metadata": {},
   "source": [
    "18) Change the first character of each word to upper case in each word of ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c210bbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     How\n",
      "1      To\n",
      "2    Kick\n",
      "3    Ass?\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(['how', 'to', 'Kick', 'ass?'])\n",
    "ser = ser.str.capitalize()\n",
    "print(ser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4087c34",
   "metadata": {},
   "source": [
    "19) Caluculate the number of characters for each element in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "216f9a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3\n",
      "1    2\n",
      "2    4\n",
      "3    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(['how', 'to', 'Kick', 'ass?'])\n",
    "num_characters = ser.str.len()\n",
    "print(num_characters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26bcf59",
   "metadata": {},
   "source": [
    "20) Caluculate the difference of differences between the consequtive numbers of ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6dba0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    NaN\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "5    1.0\n",
      "6    0.0\n",
      "7    2.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "#The first .diff() will calculate the difference between consecutive numbers\n",
    "#the second .diff() will calculate the difference between the differences.\n",
    "diff_of_diff = ser.diff().diff()\n",
    "print(diff_of_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a008fb",
   "metadata": {},
   "source": [
    "21) Convert the date-strings to a timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db82de89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2010-01-01 00:00:00\n",
      "1   2011-02-02 00:00:00\n",
      "2   2012-03-03 00:00:00\n",
      "3   2013-04-04 00:00:00\n",
      "4   2014-05-05 00:00:00\n",
      "5   2015-06-06 12:20:00\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "ser = pd.to_datetime(ser)\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db7a603",
   "metadata": {},
   "source": [
    "22) Get the day of month, week number, day of year and day of week from ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4bcc124e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day of Month:  0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "dtype: int64 Week Number:  0    53\n",
      "1     5\n",
      "2     9\n",
      "3    14\n",
      "4    19\n",
      "5    23\n",
      "Name: week, dtype: UInt32 Day of Year:  0      1\n",
      "1     33\n",
      "2     63\n",
      "3     94\n",
      "4    125\n",
      "5    157\n",
      "dtype: int64 Day of Week:  0    4\n",
      "1    2\n",
      "2    5\n",
      "3    3\n",
      "4    0\n",
      "5    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "ser = pd.to_datetime(ser)\n",
    "#.dt accessor after converting the date strings to timestamp to extract different date attributes from the series\n",
    "day_of_month = ser.dt.day\n",
    "week_number = ser.dt.isocalendar().week #get the week number.\n",
    "day_of_year = ser.dt.dayofyear\n",
    "day_of_week = ser.dt.weekday\n",
    "print(\"Day of Month: \", day_of_month, \"Week Number: \", week_number, \"Day of Year: \", day_of_year, \"Day of Week: \", day_of_week)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c9dab",
   "metadata": {},
   "source": [
    "23) Change ser to dates that start with 4th of the respective months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a6384074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2010-01-04\n",
      "1   2011-02-04\n",
      "2   2012-03-04\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n",
    "ser = pd.to_datetime(\"4 \" + ser, format=\"%d %b %Y\")\n",
    "print(ser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129cbbd7",
   "metadata": {},
   "source": [
    "24) From ser, extract words that contain at least 2 vowels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184fdd69",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32dec09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Apple\n",
      "1    Orange\n",
      "4     Money\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "result = ser[ser.str.contains(r'[aeiou].*[aeiou]', case=False, na=False)]\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44177063",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ff84fb4",
   "metadata": {},
   "source": [
    "25) Extract the valid emails from the series emails. The regex pattern for valid emails is provided as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e85fe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    rameses@egypt.com\n",
      "2           matt@t.com\n",
      "3    narendra@modi.com\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.com', 'narendra@modi.com'])\n",
    "pattern = '([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4})'\n",
    "valid_emails = emails.str.extract(pattern, expand=False)\n",
    "valid_emails = valid_emails.dropna()\n",
    "print(valid_emails)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6b21b",
   "metadata": {},
   "source": [
    "26) Compute the mean of weights of each fruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "75855cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fruit\n",
      "apple     6.500000\n",
      "banana    4.333333\n",
      "carrot    5.333333\n",
      "Name: weights, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "\n",
    "# Create a dataframe from the fruit and weights series\n",
    "df = pd.DataFrame({'fruit': fruit, 'weights': weights})\n",
    "\n",
    "# Group the dataframe by fruit and compute the mean of each group\n",
    "mean_weights = df.groupby('fruit')['weights'].mean()\n",
    "print(mean_weights)\n",
    "\n",
    "#examples\n",
    "#> [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "#> ['banana', 'carrot', 'apple', 'carrot', 'carrot', 'apple', 'banana', 'carrot', 'apple', 'carrot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a486fbb3",
   "metadata": {},
   "source": [
    "27) Compute the euclidean distance between series (points) p and q, without using a packaged formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c9cbfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.16590212458495\n"
     ]
    }
   ],
   "source": [
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "import numpy as np\n",
    "distance = np.linalg.norm(p - q)\n",
    "print(distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f76ff",
   "metadata": {},
   "source": [
    "28) Get the positions of peaks (values surrounded by smaller values on both sides) in ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ea30aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "peaks = []\n",
    "for i in range(1, len(ser)-1):\n",
    "    if ser[i] > ser[i-1] and ser[i] > ser[i+1]:\n",
    "        peaks.append(i)\n",
    "print(peaks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138213f6",
   "metadata": {},
   "source": [
    "29) Replace the spaces in my_str with the least frequent character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1d4aff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbccdebcabedcgade\n"
     ]
    }
   ],
   "source": [
    "my_str = 'dbc deb abed gade'\n",
    "char_count = {}\n",
    "for char in my_str:\n",
    "    if char != ' ':\n",
    "        char_count[char] = char_count.get(char, 0) + 1\n",
    "least_frequent_char = min(char_count, key=char_count.get)\n",
    "my_str = my_str.replace(' ', least_frequent_char)\n",
    "print(my_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64971c0",
   "metadata": {},
   "source": [
    "30) Create a timeseries starting at ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4cd8dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01    98\n",
      "2000-01-08    20\n",
      "2000-01-15    84\n",
      "2000-01-22    30\n",
      "2000-01-29    98\n",
      "2000-02-05    58\n",
      "2000-02-12    37\n",
      "2000-02-19    62\n",
      "2000-02-26    81\n",
      "2000-03-04    93\n",
      "2000-03-11    43\n",
      "Freq: W-SAT, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a start date of '2000-01-01'\n",
    "start_date = pd.to_datetime('2000-01-01')\n",
    "\n",
    "# create an end date that is 10 weekends (saturdays) after the start date\n",
    "end_date = start_date + pd.offsets.Week(10)\n",
    "\n",
    "# create a date range of weekends from start to end date\n",
    "weekends = pd.date_range(start=start_date, end=end_date, freq='W-SAT')\n",
    "\n",
    "# create a series with random integers as values and the weekends as index\n",
    "ser = pd.Series(np.random.randint(0,100, size=len(weekends)), index=weekends)\n",
    "\n",
    "# print the series\n",
    "print(ser)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a17176",
   "metadata": {},
   "source": [
    "31) Series ser has missing dates and values. Make all missing dates appear and fill up with value from previous date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c8a10d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-02     1.0\n",
      "2000-01-03    10.0\n",
      "2000-01-04    10.0\n",
      "2000-01-05    10.0\n",
      "2000-01-06     3.0\n",
      "2000-01-07     3.0\n",
      "2000-01-08     3.0\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the series with missing dates and values\n",
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "\n",
    "# Reindex the series with all dates between the first and last date in the series\n",
    "ser = ser.reindex(pd.date_range(start=ser.index[0], end=ser.index[-1]))\n",
    "\n",
    "# Forward fill the missing values with the previous value\n",
    "ser.fillna(method='ffill', inplace=True)\n",
    "\n",
    "print(ser)\n",
    "\n",
    "#> 2000-01-01     1.0\n",
    "#> 2000-01-03    10.0\n",
    "#> 2000-01-06     3.0\n",
    "#> 2000-01-08     NaN\n",
    "#> dtype: float64\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c09b3",
   "metadata": {},
   "source": [
    "32) Compute autocorrelations for the first 10 lags of ser. Find out which lag has the largest correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052982b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ae48ebc",
   "metadata": {},
   "source": [
    "33) Import every 50th row of BostonHousing dataset as a dataframe.\n",
    "    https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09888bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f10cbec",
   "metadata": {},
   "source": [
    "34) Import the boston housing dataset, but while importing change the 'medv' (median house value) column so that values < 25 becomes ‘Low’ and > 25 becomes ‘High’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c39256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a83078db",
   "metadata": {},
   "source": [
    "35) Create a dataframe with rows as strides from the series \"L\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9dfeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = pd.Series(range(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36f890",
   "metadata": {},
   "source": [
    "36) Import ‘crim’ and ‘medv’ columns of the BostonHousing dataset as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ecddbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d830c591",
   "metadata": {},
   "source": [
    "37) Get the number of rows, columns, datatype and summary statistics of each column of the Cars93 dataset. Also get the numpy array and list equivalent of the dataframe.\n",
    "\n",
    "https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fe83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e458e997",
   "metadata": {},
   "source": [
    "38) Which manufacturer, model and type has the highest Price? What is the row and column number of the cell with the highest Price value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70df19d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4e81856",
   "metadata": {},
   "source": [
    "39) Rename the column \"Type\" as \"CarType\" in the previous data and replace the ‘.’ in column names with ‘_’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e517e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5989022c",
   "metadata": {},
   "source": [
    "40) Check if the data from #37 has any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f7e0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed881438",
   "metadata": {},
   "source": [
    "41) Count the number of missing values in each column of the previous data. Which column has the maximum number of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf14525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5abbc84",
   "metadata": {},
   "source": [
    "42) Replace missing values in Min.Price and Max.Price columns with their respective mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91acfe3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1d26407",
   "metadata": {},
   "source": [
    "43) In the previous data, use apply method to replace the missing values in Min.Price with the column’s mean and those in Max.Price with the column’s median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6209b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80c193bc",
   "metadata": {},
   "source": [
    "44) Get the first column (a) in the data as a dataframe (rather than as a Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2fbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83334c4f",
   "metadata": {},
   "source": [
    "45) Actually 3 questions.\n",
    "\n",
    "In the data, interchange columns 'a' and 'c'.\n",
    "\n",
    "Create a generic function to interchange two columns, without hardcoding column names.\n",
    "\n",
    "Sort the columns in reverse alphabetical order, that is colume 'e' first through column 'a' last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706e8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd957988",
   "metadata": {},
   "source": [
    "46) Change the pandas display settings on printing the dataframe so it shows a maximum of 10 rows and 10 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd512a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f69a323b",
   "metadata": {},
   "source": [
    "47) Suppress scientific notations like ‘e-03’ in df and print upto 4 numbers after decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485aa0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfa22aec",
   "metadata": {},
   "source": [
    "48) Format the values in column 'random' of df as percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d4f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "df\n",
    "#>      random\n",
    "#> 0    .689723\n",
    "#> 1    .957224\n",
    "#> 2    .159157\n",
    "#> 3    .21082"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829030ce",
   "metadata": {},
   "source": [
    "49) From the cars data, filter the 'Manufacturer', 'Model' and 'Type' for every 20th row starting from 1st (row 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439593c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d38155b7",
   "metadata": {},
   "source": [
    "50) In the cars data, Replace NaNs with ‘missing’ in columns 'Manufacturer', 'Model' and 'Type' and create a index as a combination of these three columns and check if the index is a primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf131e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d01c9b73",
   "metadata": {},
   "source": [
    "51) Find the row position of the 5th largest value of column 'a' in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15321302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df76d19",
   "metadata": {},
   "source": [
    "52) In ser, find the position of the 2nd largest value greater than the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61330d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.randint(1, 100, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaae1b8",
   "metadata": {},
   "source": [
    "53) Get the last two rows of df whose row sum is greater than 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab30612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4dac7e",
   "metadata": {},
   "source": [
    "54) Replace all values of ser in the lower 5%ile and greater than 95%ile with respective 5th and 95th %ile value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.logspace(-2, 2, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407723d9",
   "metadata": {},
   "source": [
    "55) Reshape df to the largest possible square with negative values removed. Drop the smallest values if need be. The order of the positive numbers in the result should remain the same as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa891f3",
   "metadata": {},
   "source": [
    "56) Swap rows 1 and 2 in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca60052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97144928",
   "metadata": {},
   "source": [
    "57) Reverse all the rows of dataframe df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09f84f",
   "metadata": {},
   "source": [
    "58) Get one-hot encodings for column 'a' in the dataframe df and append it as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59860b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde'))\n",
    "    a   b   c   d   e\n",
    "0   0   1   2   3   4\n",
    "1   5   6   7   8   9\n",
    "2  10  11  12  13  14\n",
    "3  15  16  17  18  19\n",
    "4  20  21  22  23  24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5295b8b",
   "metadata": {},
   "source": [
    "59) Obtain the column name with the highest number of row-wise maximum’s in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fcf24b",
   "metadata": {},
   "source": [
    "60) Create a new column such that, each row contains the row number of nearest row-record by euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0719c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
    "df\n",
    "#     p   q   r   s\n",
    "# a  57  77  13  62\n",
    "# b  68   5  92  24\n",
    "# c  74  40  18  37\n",
    "# d  80  17  39  60\n",
    "# e  93  48  85  33\n",
    "# f  69  55   8  11\n",
    "# g  39  23  88  53\n",
    "# h  63  28  25  61\n",
    "# i  18   4  73   7\n",
    "# j  79  12  45  34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb1791",
   "metadata": {},
   "source": [
    "61) Compute maximum possible absolute correlation value of each column against other columns in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ef471",
   "metadata": {},
   "source": [
    "62) Compute the minimum-by-maximum for every row of df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7368340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d2276",
   "metadata": {},
   "source": [
    "63) Create a new column 'penultimate' which has the second largest value of each row of df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c1042",
   "metadata": {},
   "source": [
    "64) Normalize all columns of df by subtracting the column mean and divide by standard deviation.\n",
    "Range all columns of df such that the minimum value in each column is 0 and max is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da28502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26e808",
   "metadata": {},
   "source": [
    "65) Compute the correlation of each row of df with its succeeding row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fca730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57341a09",
   "metadata": {},
   "source": [
    "66) Replace both values in both diagonals of df with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721432ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\n",
    "df\n",
    "#     0   1   2   3   4   5   6   7   8   9\n",
    "# 0  11  46  26  44  11  62  18  70  68  26\n",
    "# 1  87  71  52  50  81  43  83  39   3  59\n",
    "# 2  47  76  93  77  73   2   2  16  14  26\n",
    "# 3  64  18  74  22  16  37  60   8  66  39\n",
    "# 4  10  18  39  98  25   8  32   6   3  29\n",
    "# 5  29  91  27  86  23  84  28  31  97  10\n",
    "# 6  37  71  70  65   4  72  82  89  12  97\n",
    "# 7  65  22  97  75  17  10  43  78  12  77\n",
    "# 8  47  57  96  55  17  83  61  85  26  86\n",
    "# 9  76  80  28  45  77  12  67  80   7  63\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c483b",
   "metadata": {},
   "source": [
    "67) Using a key in a grouped data frame. From df_grouped, get the group belonging to 'apple' as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8028ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'col2': np.random.rand(9),\n",
    "                   'col3': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df_grouped = df.groupby(['col1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cb901",
   "metadata": {},
   "source": [
    "68) In df, find the second largest value of 'taste' for 'banana'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde89cb",
   "metadata": {},
   "source": [
    "69) In df, Compute the mean price of every fruit, while keeping the fruit as another column instead of an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a4c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eaa372",
   "metadata": {},
   "source": [
    "70) Join dataframes df1 and df2 by ‘fruit-pazham’ and ‘weight-kilo’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a250adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'kilo': ['high', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 6)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57adb8fe",
   "metadata": {},
   "source": [
    "71) Get the positions where the value of two columns match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43cc070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fruit1': np.random.choice(['apple', 'orange', 'banana'], 10),\n",
    "                    'fruit2': np.random.choice(['apple', 'orange', 'banana'], 10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da5c86",
   "metadata": {},
   "source": [
    "72) Create two new columns in df, one of which is a lag1 (shift column a down by 1 row) of column ‘a’ and the other is a lead1 (shift column b up by 1 row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e531adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))\n",
    "\n",
    "    a   b   c   d\n",
    "0  66  34  76  47\n",
    "1  20  86  10  81\n",
    "2  75  73  51  28\n",
    "3   1   1   9  83\n",
    "4  30  47  67   4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a01f7",
   "metadata": {},
   "source": [
    "73) Get the frequency of unique values in the entire dataframe df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b1df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d182d",
   "metadata": {},
   "source": [
    "74) Split the string column in df to form a dataframe with 3 columns as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\"STD, City    State\",\n",
    "\"33, Kolkata    West Bengal\",\n",
    "\"44, Chennai    Tamil Nadu\",\n",
    "\"40, Hyderabad    Telengana\",\n",
    "\"80, Bangalore    Karnataka\"], columns=['row'])\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4ec0df32e04b05f4fde933a444e336c86f4396636f275791ee27a5768d2e3f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
