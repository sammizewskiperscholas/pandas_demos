{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a8dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4bd4f0",
   "metadata": {},
   "source": [
    "1) Demonstrate how to import Pandas and check the version of the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3bc97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Learner_XZHCG221\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit           : 8dab54d6573f7186ff0c3b6364d5e4dd635ff3e7\n",
      "python           : 3.11.0.final.0\n",
      "python-bits      : 64\n",
      "OS               : Windows\n",
      "OS-release       : 10\n",
      "Version          : 10.0.22621\n",
      "machine          : AMD64\n",
      "processor        : Intel64 Family 6 Model 140 Stepping 1, GenuineIntel\n",
      "byteorder        : little\n",
      "LC_ALL           : None\n",
      "LANG             : None\n",
      "LOCALE           : English_United States.1252\n",
      "\n",
      "pandas           : 1.5.2\n",
      "numpy            : 1.24.1\n",
      "pytz             : 2022.6\n",
      "dateutil         : 2.8.2\n",
      "setuptools       : 65.5.0\n",
      "pip              : 22.3.1\n",
      "Cython           : None\n",
      "pytest           : None\n",
      "hypothesis       : None\n",
      "sphinx           : None\n",
      "blosc            : None\n",
      "feather          : None\n",
      "xlsxwriter       : None\n",
      "lxml.etree       : None\n",
      "html5lib         : None\n",
      "pymysql          : None\n",
      "psycopg2         : None\n",
      "jinja2           : 3.1.2\n",
      "IPython          : 8.7.0\n",
      "pandas_datareader: None\n",
      "bs4              : 4.11.1\n",
      "bottleneck       : None\n",
      "brotli           : None\n",
      "fastparquet      : None\n",
      "fsspec           : None\n",
      "gcsfs            : None\n",
      "matplotlib       : 3.6.3\n",
      "numba            : None\n",
      "numexpr          : None\n",
      "odfpy            : None\n",
      "openpyxl         : None\n",
      "pandas_gbq       : None\n",
      "pyarrow          : None\n",
      "pyreadstat       : None\n",
      "pyxlsb           : None\n",
      "s3fs             : None\n",
      "scipy            : 1.10.0\n",
      "snappy           : None\n",
      "sqlalchemy       : None\n",
      "tables           : None\n",
      "tabulate         : None\n",
      "xarray           : None\n",
      "xlrd             : None\n",
      "xlwt             : None\n",
      "zstandard        : None\n",
      "tzdata           : None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.__version__ #dunder method\n",
    "pd.show_versions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc4f4a",
   "metadata": {},
   "source": [
    "2) Transform this list, numpy array, and dictionary into a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b30b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     0\n",
       "b     1\n",
       "c     2\n",
       "e     3\n",
       "d     4\n",
       "f     5\n",
       "g     6\n",
       "h     7\n",
       "i     8\n",
       "j     9\n",
       "k    10\n",
       "l    11\n",
       "m    12\n",
       "n    13\n",
       "o    14\n",
       "p    15\n",
       "q    16\n",
       "r    17\n",
       "s    18\n",
       "t    19\n",
       "u    20\n",
       "v    21\n",
       "w    22\n",
       "x    23\n",
       "y    24\n",
       "z    25\n",
       "dtype: int32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "s_list= pd.Series(mylist)\n",
    "\n",
    "myarr = np.arange(26)\n",
    "s_myarr= pd.Series(myarr)\n",
    "\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "s_mydict= pd.Series(mydict)\n",
    "\n",
    "s_mydict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17155a8",
   "metadata": {},
   "source": [
    "3) Convert the index of your previous series into a column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0f1395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  0\n",
      "0     a  0\n",
      "1     b  1\n",
      "2     c  2\n",
      "3     e  3\n",
      "4     d  4\n"
     ]
    }
   ],
   "source": [
    "df = s_mydict.to_frame().reset_index()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f625f24",
   "metadata": {},
   "source": [
    "4) Combine the series below into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d268747c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))\n",
    "\n",
    "df= pd.concat([ser1,ser2], axis=1)\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd8618",
   "metadata": {},
   "source": [
    "5) Give the series below a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b18f9c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "1     b\n",
       "2     c\n",
       "3     e\n",
       "4     d\n",
       "5     f\n",
       "6     g\n",
       "7     h\n",
       "8     i\n",
       "9     j\n",
       "10    k\n",
       "11    l\n",
       "12    m\n",
       "13    n\n",
       "14    o\n",
       "15    p\n",
       "16    q\n",
       "17    r\n",
       "18    s\n",
       "19    t\n",
       "20    u\n",
       "21    v\n",
       "22    w\n",
       "23    x\n",
       "24    y\n",
       "25    z\n",
       "Name: Series, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'), name= 'Series')\n",
    "\n",
    "ser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8d244",
   "metadata": {},
   "source": [
    "6) Find the elements in the first series (ser1) not in the second series (ser2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f1276978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    4\n",
       "4    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "list1= []\n",
    "list2= []\n",
    "for i in ser1:\n",
    "    list1.append(i)\n",
    "for i in ser2:\n",
    "    list2.append(i)\n",
    "\n",
    "list3= []\n",
    "for num in list1:\n",
    "    if num not in list2:\n",
    "        list3.append(num)\n",
    "\n",
    "print(list3)\n",
    "\n",
    "ser1[~ser1.isin(ser2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d336f7dd",
   "metadata": {},
   "source": [
    "7) Find the elements in both series that are not in common (remove them if they exist in both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28768232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "7    6\n",
       "8    7\n",
       "9    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "ser_concat= pd.concat([ser1,ser2],ignore_index=True)\n",
    "ser3= ser1[ser1.isin(ser2)]\n",
    "ser_concat[~ser_concat.isin(ser3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7188b5",
   "metadata": {},
   "source": [
    "8) Find the minimum, max, 25th percentile, and 75th percentile in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a1a3ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: -5.432440396089653 Maximum: 19.513155967544968 25th percentile: 7.434060187569492 75th percentile: 11.130143349442168\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.normal(10, 5, 25))\n",
    "ser_min= ser.min()\n",
    "ser_max= ser.max()\n",
    "ser_25th= ser.quantile(.25)\n",
    "ser_75th=ser.quantile(.75)\n",
    "print(\"Minimum:\",ser_min, \"Maximum:\",ser_max, \"25th percentile:\",ser_25th, \"75th percentile:\",ser_75th)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c1803",
   "metadata": {},
   "source": [
    "9) Obtain the count of each unique item in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "16a2880a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e    7\n",
       "g    7\n",
       "h    5\n",
       "f    3\n",
       "c    2\n",
       "d    2\n",
       "a    2\n",
       "b    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n",
    "ser.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449036ea",
   "metadata": {},
   "source": [
    "10) Keep the two most frequent items in the series and change all items that are not those two into \"Other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e86f2a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         3\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4     Other\n",
       "5         1\n",
       "6     Other\n",
       "7         3\n",
       "8         3\n",
       "9         1\n",
       "10        1\n",
       "11        3\n",
       "dtype: object"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "ser.value_counts()\n",
    "\n",
    "ser[~ser.isin(ser.value_counts().index[:2])] = 'Other'\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5928875",
   "metadata": {},
   "source": [
    "11) Bin the series below into 10 equal deciles and replace the values with the bin name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "979b3d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      4th\n",
       "1      6th\n",
       "2      1st\n",
       "3      1st\n",
       "4      2nd\n",
       "5      8th\n",
       "6      2nd\n",
       "7     10th\n",
       "8      3rd\n",
       "9      6th\n",
       "10     5th\n",
       "11     5th\n",
       "12     7th\n",
       "13     9th\n",
       "14     7th\n",
       "15     4th\n",
       "16     3rd\n",
       "17    10th\n",
       "18     9th\n",
       "19     8th\n",
       "dtype: category\n",
       "Categories (10, object): ['1st' < '2nd' < '3rd' < '4th' ... '7th' < '8th' < '9th' < '10th']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.random.random(20))\n",
    "ser2= np.percentile(ser, [0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1])\n",
    "bin_names= ['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th']\n",
    "pd.qcut(ser, q=[0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1], labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee79a87",
   "metadata": {},
   "source": [
    "12) Reshape the series ser into a dataframe with 7 rows and 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "17a3513a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  7  5  8  4  5\n",
       "1  3  2  4  8  7\n",
       "2  3  1  5  4  4\n",
       "3  3  2  5  8  8\n",
       "4  2  6  8  7  8\n",
       "5  3  8  1  6  3\n",
       "6  8  5  8  4  7"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "df=pd.DataFrame(ser.values.reshape(7,5))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c62e92",
   "metadata": {},
   "source": [
    "13) Find the positions of numbers that are multiples of 3 from ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7ae884a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    9\n",
      "1    8\n",
      "2    9\n",
      "3    5\n",
      "4    5\n",
      "5    6\n",
      "6    7\n",
      "dtype: int32\n",
      "[9, 9, 6]\n",
      "0    9\n",
      "2    9\n",
      "5    6\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "print(ser)\n",
    "list1= []\n",
    "for i in ser:\n",
    "    if i%3 ==0:\n",
    "        list1.append(i)\n",
    "\n",
    "print(list1)\n",
    "\n",
    "\n",
    "ser3 = ser[(ser%3==0)]\n",
    "print(ser3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60f247",
   "metadata": {},
   "source": [
    "14) From ser, extract the items at positions in list pos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "42338aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "4     e\n",
       "8     i\n",
       "14    o\n",
       "20    u\n",
       "dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]\n",
    "\n",
    "ser.take(pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1836c",
   "metadata": {},
   "source": [
    "15) Stack ser1 and ser2 vertically and horizontally (to form a dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5dfea534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  0  a\n",
       "1  1  b\n",
       "2  2  c\n",
       "3  3  d\n",
       "4  4  e"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "pd.concat([ser1,ser2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c252d7bb",
   "metadata": {},
   "source": [
    "16) Get the positions of items of ser2 in ser1 as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "da51891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 0, 8]\n"
     ]
    }
   ],
   "source": [
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])\n",
    "\n",
    "pos= []\n",
    "for i in range(len(ser2)):\n",
    "    for j in range(len(ser1)):\n",
    "        if ser2[i]==ser1[j]:\n",
    "            pos.append(j)\n",
    "\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098e34c8",
   "metadata": {},
   "source": [
    "17) Compute the mean squared error of truth and pred series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "df7ff599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3381832286239441"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)\n",
    "\n",
    "np.mean((truth-pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf6f79",
   "metadata": {},
   "source": [
    "18) Change the first character of each word to upper case in each word of ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c210bbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     How\n",
       "1      To\n",
       "2    Kick\n",
       "3    Ass?\n",
       "dtype: object"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "\n",
    "ser.str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f198a",
   "metadata": {},
   "source": [
    "19) Caluculate the number of characters for each element in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "216f9a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    4\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "#ser.map(lambda x: len(x))\n",
    "\n",
    "ser.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26bcf59",
   "metadata": {},
   "source": [
    "20) Caluculate the difference of differences between the consequtive numbers of ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c6dba0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-116"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "\n",
    "ser.diff().diff().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a2901",
   "metadata": {},
   "source": [
    "21) Convert the date-strings to a timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "db82de89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-01 00:00:00\n",
       "1   2011-02-02 00:00:00\n",
       "2   2012-03-03 00:00:00\n",
       "3   2013-04-04 00:00:00\n",
       "4   2014-05-05 00:00:00\n",
       "5   2015-06-06 12:20:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "pd.to_datetime(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f83c0",
   "metadata": {},
   "source": [
    "22) Get the day of month, week number, day of year and day of week from ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bcc124e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Learner_XZHCG221\\AppData\\Local\\Temp\\ipykernel_21012\\617606420.py:4: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  weeks=dates.dt.week\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01 Jan 2010</td>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-02-2011</td>\n",
       "      <td>2011-02-02 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20120303</td>\n",
       "      <td>2012-03-03 00:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013/04/04</td>\n",
       "      <td>2013-04-04 00:00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>2014-05-05 00:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-06-06T12:20</td>\n",
       "      <td>2015-06-06 12:20:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0                   1   2  3    4  5\n",
       "0       01 Jan 2010 2010-01-01 00:00:00  53  1    1  4\n",
       "1        02-02-2011 2011-02-02 00:00:00   5  2   33  2\n",
       "2          20120303 2012-03-03 00:00:00   9  3   63  5\n",
       "3        2013/04/04 2013-04-04 00:00:00  14  4   94  3\n",
       "4        2014-05-05 2014-05-05 00:00:00  19  5  125  0\n",
       "5  2015-06-06T12:20 2015-06-06 12:20:00  23  6  157  5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "dates= pd.to_datetime(ser)\n",
    "weeks=dates.dt.week\n",
    "days=dates.dt.day\n",
    "day_of_year=dates.dt.dayofyear\n",
    "day_of_week= dates.dt.dayofweek\n",
    "pd.concat([ser,dates,weeks,days,day_of_year, day_of_week],axis=1).rename(columns={'0': 'Original Dates','1':'Timeseries', '2':'Week Number', '3': 'Day of Month', '4': 'Day of Year', '5': 'Day of Week'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f97b7",
   "metadata": {},
   "source": [
    "23) Change ser to dates that start with 4th of the respective months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6384074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jan 04 2010', 'Feb 04 2011', 'Mar 04 2012']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from dateutil.parser import parse\n",
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n",
    "\n",
    "dates= []\n",
    "dates2= []\n",
    "for x in ser:\n",
    "    dates.append(x.split()) #split string into Month & Year\n",
    "for string in dates:\n",
    "    new_string=\" 04 \".join(string) #Joing the string back together with \" 04 \"\n",
    "    dates2.append(new_string) #Add to a new list\n",
    "\n",
    "dates2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb2f54",
   "metadata": {},
   "source": [
    "24) From ser, extract words that contain at least 2 vowels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "32dec09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Apple\n",
      "1    Orange\n",
      "4     Money\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "vowels= ['a', 'e', 'i', 'o', 'u']\n",
    "\n",
    "lists= []\n",
    "new_list= []\n",
    "for i in ser:\n",
    "    lists.append(i.lower())\n",
    "\n",
    "for word in lists:\n",
    "    count= 0\n",
    "    for letter in word:\n",
    "        if letter in vowels:\n",
    "            count= count+1\n",
    "            if count >=2 and word not in new_list:\n",
    "                new_list.append(word)\n",
    "\n",
    "\n",
    "#new_list\n",
    "\n",
    "ser2= ser[ser.str.count(pat=r'[AaEeIioOUu]') >= 2]\n",
    "ser[ser.str.count(pat=r'[AaEeIiOoUu]', flags=re) >= 2]\n",
    "\n",
    "print(ser2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44177063",
   "metadata": {},
   "source": [
    "25) Extract the valid emails from the series emails. The regex pattern for valid emails is provided as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e85fe14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     []\n",
       "1    [rameses@egypt.com]\n",
       "2            [matt@t.co]\n",
       "3    [narendra@modi.com]\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "\n",
    "emails.str.findall(pattern,flags=re.IGNORECASE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fadf17",
   "metadata": {},
   "source": [
    "26) Compute the mean of weights of each fruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75855cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "['apple', 'apple', 'apple', 'banana', 'carrot', 'carrot', 'carrot', 'banana', 'carrot', 'apple']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "apple     4.00\n",
       "banana    6.00\n",
       "carrot    6.75\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "print(weights.tolist())\n",
    "print(fruit.tolist())\n",
    "#examples\n",
    "#> [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "#> ['banana', 'carrot', 'apple', 'carrot', 'carrot', 'apple', 'banana', 'carrot', 'apple', 'carrot']\n",
    "\n",
    "fruit_weight=weights.groupby(fruit).mean()\n",
    "fruit_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c8ebe7",
   "metadata": {},
   "source": [
    "27) Compute the euclidean distance between series (points) p and q, without using a packaged formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c9cbfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.16590212458495"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "\n",
    "sum((p-q)**2)**.5\n",
    "\n",
    "#Euclidean Distance - distance between 2 points\n",
    "#First sum all the values then find the difference\n",
    "#square the difference\n",
    "#square root of the difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8326a3",
   "metadata": {},
   "source": [
    "28) Get the positions of peaks (values surrounded by smaller values on both sides) in ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ea30aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    8.0\n",
       "2   -7.0\n",
       "3    1.0\n",
       "4    5.0\n",
       "5    1.0\n",
       "6   -8.0\n",
       "7    5.0\n",
       "8   -4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "ser.diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f5675f",
   "metadata": {},
   "source": [
    "29) Replace the spaces in my_str with the least frequent character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d4aff8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dbcgdebgabedggade'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str = 'dbc deb abed gade'\n",
    "ser= pd.Series(list(my_str)) #trun string into series and make into list\n",
    "freq= ser.value_counts() #get count of unique letters(mus be a series)\n",
    "least_freq= freq.index[-1] #get least frequent value\n",
    "least_freq\n",
    "\"\".join(ser.replace(' ',least_freq)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b95f0",
   "metadata": {},
   "source": [
    "30) Create a timeseries starting at ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e4cd8dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    6\n",
       "2000-01-08    6\n",
       "2000-01-15    5\n",
       "2000-01-22    5\n",
       "2000-01-29    8\n",
       "2000-02-05    3\n",
       "2000-02-12    8\n",
       "2000-02-19    3\n",
       "2000-02-26    8\n",
       "2000-03-04    4\n",
       "Freq: W-SAT, dtype: int32"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8a17176",
   "metadata": {},
   "source": [
    "31) Series ser has missing dates and values. Make all missing dates appear and fill up with value from previous date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c8a10d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-03    10.0\n",
      "2000-01-06     3.0\n",
      "2000-01-08     NaN\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000-01-01     1.0\n",
       "2000-01-02     1.0\n",
       "2000-01-03    10.0\n",
       "2000-01-04    10.0\n",
       "2000-01-05    10.0\n",
       "2000-01-06     3.0\n",
       "2000-01-07     3.0\n",
       "2000-01-08     NaN\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "print(ser)\n",
    "#> 2000-01-01     1.0\n",
    "#> 2000-01-03    10.0\n",
    "#> 2000-01-06     3.0\n",
    "#> 2000-01-08     NaN\n",
    "#> dtype: float64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b261ac",
   "metadata": {},
   "source": [
    "32) Compute autocorrelations for the first 10 lags of ser. Find out which lag has the largest correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "052982b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14, -0.09, 0.69, -0.18, -0.08, 0.69, -0.41, 0.14, 0.58, -0.3]\n",
      "Lag having highest correlation:  3\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae48ebc",
   "metadata": {},
   "source": [
    "33) Import every 50th row of BostonHousing dataset as a dataframe.\n",
    "    https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "09888bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Learner_XZHCG221\\AppData\\Local\\Temp\\ipykernel_10344\\4036275642.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\Learner_XZHCG221\\AppData\\Local\\Temp\\ipykernel_10344\\4036275642.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\Learner_XZHCG221\\AppData\\Local\\Temp\\ipykernel_10344\\4036275642.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\Learner_XZHCG221\\AppData\\Local\\Temp\\ipykernel_10344\\4036275642.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\Learner_XZHCG221\\AppData\\Local\\Temp\\ipykernel_10344\\4036275642.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\Learner_XZHCG221\\AppData\\Local\\Temp\\ipykernel_10344\\4036275642.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\Learner_XZHCG221\\AppData\\Local\\Temp\\ipykernel_10344\\4036275642.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\Learner_XZHCG221\\AppData\\Local\\Temp\\ipykernel_10344\\4036275642.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\Learner_XZHCG221\\AppData\\Local\\Temp\\ipykernel_10344\\4036275642.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\Learner_XZHCG221\\AppData\\Local\\Temp\\ipykernel_10344\\4036275642.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\Learner_XZHCG221\\AppData\\Local\\Temp\\ipykernel_10344\\4036275642.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f10cbec",
   "metadata": {},
   "source": [
    "34) Import the boston housing dataset, but while importing change the 'medv' (median house value) column so that values < 25 becomes ‘Low’ and > 25 becomes ‘High’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c9c39256",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BostonHousing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[171], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mBostonHousing.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     reader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mreader(f)\n\u001b[0;32m      4\u001b[0m     out \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Learner_XZHCG221\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BostonHousing.csv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a83078db",
   "metadata": {},
   "source": [
    "35) Create a dataframe with rows as strides from the series \"L\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ea9dfeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 2,  3,  4,  5],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 6,  7,  8,  9],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [10, 11, 12, 13]], dtype=int64)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b36f890",
   "metadata": {},
   "source": [
    "36) Import ‘crim’ and ‘medv’ columns of the BostonHousing dataset as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "33ecddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  medv\n",
      "0  0.00632  24.0\n",
      "1  0.02731  21.6\n",
      "2  0.02729  34.7\n",
      "3  0.03237  33.4\n",
      "4  0.06905  36.2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d830c591",
   "metadata": {},
   "source": [
    "37) Get the number of rows, columns, datatype and summary statistics of each column of the Cars93 dataset. Also get the numpy array and list equivalent of the dataframe.\n",
    "\n",
    "https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2c1fe83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 27)\n",
      "Manufacturer           object\n",
      "Model                  object\n",
      "Type                   object\n",
      "Min.Price             float64\n",
      "Price                 float64\n",
      "Max.Price             float64\n",
      "MPG.city              float64\n",
      "MPG.highway           float64\n",
      "AirBags                object\n",
      "DriveTrain             object\n",
      "Cylinders              object\n",
      "EngineSize            float64\n",
      "Horsepower            float64\n",
      "RPM                   float64\n",
      "Rev.per.mile          float64\n",
      "Man.trans.avail        object\n",
      "Fuel.tank.capacity    float64\n",
      "Passengers            float64\n",
      "Length                float64\n",
      "Wheelbase             float64\n",
      "Width                 float64\n",
      "Turn.circle           float64\n",
      "Rear.seat.room        float64\n",
      "Luggage.room          float64\n",
      "Weight                float64\n",
      "Origin                 object\n",
      "Make                   object\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'get_dtype_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[174], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mdtypes)\n\u001b[1;32m----> 6\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39;49mget_dtype_counts())\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mdtypes\u001b[39m.\u001b[39mvalue_counts())\n\u001b[0;32m      9\u001b[0m df_stats \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdescribe()\n",
      "File \u001b[1;32mc:\\Users\\Learner_XZHCG221\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'get_dtype_counts'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e458e997",
   "metadata": {},
   "source": [
    "38) Which manufacturer, model and type has the highest Price? What is the row and column number of the cell with the highest Price value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f70df19d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'get_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[175], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m df\u001b[39m.\u001b[39miloc[row[\u001b[39m0\u001b[39m], col[\u001b[39m0\u001b[39m]]\n\u001b[0;32m      7\u001b[0m df\u001b[39m.\u001b[39mat[row[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mPrice\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m df\u001b[39m.\u001b[39;49mget_value(row[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mPrice\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Learner_XZHCG221\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'get_value'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e81856",
   "metadata": {},
   "source": [
    "39) Rename the column \"Type\" as \"CarType\" in the previous data and replace the ‘.’ in column names with ‘_’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "33e517e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n",
      "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
      "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
      "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
      "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
      "       'Make'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5989022c",
   "metadata": {},
   "source": [
    "40) Check if the data from #37 has any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e9f7e0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed881438",
   "metadata": {},
   "source": [
    "41) Count the number of missing values in each column of the previous data. Which column has the maximum number of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf14525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5abbc84",
   "metadata": {},
   "source": [
    "42) Replace missing values in Min.Price and Max.Price columns with their respective mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91acfe3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1d26407",
   "metadata": {},
   "source": [
    "43) In the previous data, use apply method to replace the missing values in Min.Price with the column’s mean and those in Max.Price with the column’s median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Min.Price': np.nanmean, 'Max.Price': np.nanmedian}\n",
    "df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x, d: x.fillna(d[x.name](x)), args=(d, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c193bc",
   "metadata": {},
   "source": [
    "44) Get the first column (a) in the data as a dataframe (rather than as a Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[['a']])\n",
    "type(df.loc[:, ['a']])\n",
    "type(df.iloc[:, [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83334c4f",
   "metadata": {},
   "source": [
    "45) Actually 3 questions.\n",
    "\n",
    "In the data, interchange columns 'a' and 'c'.\n",
    "\n",
    "Create a generic function to interchange two columns, without hardcoding column names.\n",
    "\n",
    "Sort the columns in reverse alphabetical order, that is colume 'e' first through column 'a' last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "\n",
    "df[list('cbade')]\n",
    "\n",
    "\n",
    "def switch_columns(df, col1=None, col2=None):\n",
    "    colnames = df.columns.tolist()\n",
    "    i1, i2 = colnames.index(col1), colnames.index(col2)\n",
    "    colnames[i2], colnames[i1] = colnames[i1], colnames[i2]\n",
    "    return df[colnames]\n",
    "\n",
    "df1 = switch_columns(df, 'a', 'c')\n",
    "\n",
    "df[sorted(df.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd957988",
   "metadata": {},
   "source": [
    "46) Change the pandas display settings on printing the dataframe so it shows a maximum of 10 rows and 10 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a323b",
   "metadata": {},
   "source": [
    "47) Suppress scientific notations like ‘e-03’ in df and print upto 4 numbers after decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485aa0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: '%.4f' % x, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa22aec",
   "metadata": {},
   "source": [
    "48) Format the values in column 'random' of df as percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3d4f4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.859128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.709243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.957066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.663278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      random\n",
       "0  46.859128\n",
       "1   2.709243\n",
       "2  85.957066\n",
       "3  53.663278"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "df\n",
    "#>      random\n",
    "#> 0    .689723\n",
    "#> 1    .957224\n",
    "#> 2    .159157\n",
    "#> 3    .21082\n",
    "df*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829030ce",
   "metadata": {},
   "source": [
    "49) From the cars data, filter the 'Manufacturer', 'Model' and 'Type' for every 20th row starting from 1st (row 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[::20, :][['Manufacturer', 'Model', 'Type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38155b7",
   "metadata": {},
   "source": [
    "50) In the cars data, Replace NaNs with ‘missing’ in columns 'Manufacturer', 'Model' and 'Type' and create a index as a combination of these three columns and check if the index is a primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf131e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Manufacturer', 'Model', 'Type']] = df[['Manufacturer', 'Model', 'Type']].fillna('missing')\n",
    "df.index = df.Manufacturer + '_' + df.Model + '_' + df.Type\n",
    "print(df.index.is_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c9b73",
   "metadata": {},
   "source": [
    "51) Find the row position of the 5th largest value of column 'a' in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15321302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))\n",
    "n = 5\n",
    "df['a'].argsort()[::-1][n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df76d19",
   "metadata": {},
   "source": [
    "52) In ser, find the position of the 2nd largest value greater than the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "61330d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 100, 15))\n",
    "sorted_ser=sorted(ser) #sort series\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaae1b8",
   "metadata": {},
   "source": [
    "53) Get the last two rows of df whose row sum is greater than 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab30612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n",
    "rowsums = df.apply(np.sum, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4dac7e",
   "metadata": {},
   "source": [
    "54) Replace all values of ser in the lower 5%ile and greater than 95%ile with respective 5th and 95th %ile value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.logspace(-2, 2, 30))\n",
    "def cap_outliers(ser, low_perc, high_perc):\n",
    "    low, high = ser.quantile([low_perc, high_perc])\n",
    "    print(low_perc, '%ile: ', low, '|', high_perc, '%ile: ', high)\n",
    "    ser[ser < low] = low\n",
    "    ser[ser > high] = high\n",
    "    return(ser)\n",
    "\n",
    "capped_ser = cap_outliers(ser, .05, .95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407723d9",
   "metadata": {},
   "source": [
    "55) Reshape df to the largest possible square with negative values removed. Drop the smallest values if need be. The order of the positive numbers in the result should remain the same as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa891f3",
   "metadata": {},
   "source": [
    "56) Swap rows 1 and 2 in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca60052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97144928",
   "metadata": {},
   "source": [
    "57) Reverse all the rows of dataframe df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "print(df.loc[df.index[::-1], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09f84f",
   "metadata": {},
   "source": [
    "58) Get one-hot encodings for column 'a' in the dataframe df and append it as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59860b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde'))\n",
    "    a   b   c   d   e\n",
    "0   0   1   2   3   4\n",
    "1   5   6   7   8   9\n",
    "2  10  11  12  13  14\n",
    "3  15  16  17  18  19\n",
    "4  20  21  22  23  24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5295b8b",
   "metadata": {},
   "source": [
    "59) Obtain the column name with the highest number of row-wise maximum’s in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1))\n",
    "print('Column with highest row maxes: ', df.apply(np.argmax, axis=1).value_counts().index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fcf24b",
   "metadata": {},
   "source": [
    "60) Create a new column such that, each row contains the row number of nearest row-record by euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0719c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
    "df\n",
    "#     p   q   r   s\n",
    "# a  57  77  13  62\n",
    "# b  68   5  92  24\n",
    "# c  74  40  18  37\n",
    "# d  80  17  39  60\n",
    "# e  93  48  85  33\n",
    "# f  69  55   8  11\n",
    "# g  39  23  88  53\n",
    "# h  63  28  25  61\n",
    "# i  18   4  73   7\n",
    "# j  79  12  45  34\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb1791",
   "metadata": {},
   "source": [
    "61) Compute maximum possible absolute correlation value of each column against other columns in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh')\n",
    "abs_corrmat = np.abs(df.corr())\n",
    "max_corr = abs_corrmat.apply(lambda x: sorted(x)[-2])\n",
    "print('Maximum Correlation possible for each column: ', np.round(max_corr.tolist(), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ef471",
   "metadata": {},
   "source": [
    "62) Compute the minimum-by-maximum for every row of df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7368340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "min_by_max = df.apply(lambda x: np.min(x)/np.max(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d2276",
   "metadata": {},
   "source": [
    "63) Create a new column 'penultimate' which has the second largest value of each row of df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "out = df.apply(lambda x: x.sort_values().unique()[-2], axis=1)\n",
    "df['penultimate'] = out\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c1042",
   "metadata": {},
   "source": [
    "64) Normalize all columns of df by subtracting the column mean and divide by standard deviation.\n",
    "Range all columns of df such that the minimum value in each column is 0 and max is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da28502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "out1 = df.apply(lambda x: ((x - x.mean())/x.std()).round(2))\n",
    "print('Solution Q1\\n',out1)\n",
    "\n",
    "# Solution Q2\n",
    "out2 = df.apply(lambda x: ((x.max() - x)/(x.max() - x.min())).round(2))\n",
    "print('Solution Q2\\n', out2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26e808",
   "metadata": {},
   "source": [
    "65) Compute the correlation of each row of df with its succeeding row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fca730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "[df.iloc[i].corr(df.iloc[i+1]).round(2) for i in range(df.shape[0])[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57341a09",
   "metadata": {},
   "source": [
    "66) Replace both values in both diagonals of df with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721432ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\n",
    "df\n",
    "#     0   1   2   3   4   5   6   7   8   9\n",
    "# 0  11  46  26  44  11  62  18  70  68  26\n",
    "# 1  87  71  52  50  81  43  83  39   3  59\n",
    "# 2  47  76  93  77  73   2   2  16  14  26\n",
    "# 3  64  18  74  22  16  37  60   8  66  39\n",
    "# 4  10  18  39  98  25   8  32   6   3  29\n",
    "# 5  29  91  27  86  23  84  28  31  97  10\n",
    "# 6  37  71  70  65   4  72  82  89  12  97\n",
    "# 7  65  22  97  75  17  10  43  78  12  77\n",
    "# 8  47  57  96  55  17  83  61  85  26  86\n",
    "# 9  76  80  28  45  77  12  67  80   7  63\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c483b",
   "metadata": {},
   "source": [
    "67) Using a key in a grouped data frame. From df_grouped, get the group belonging to 'apple' as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8028ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'col2': np.random.rand(9),\n",
    "                   'col3': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df_grouped = df.groupby(['col1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cb901",
   "metadata": {},
   "source": [
    "68) In df, find the second largest value of 'taste' for 'banana'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde89cb",
   "metadata": {},
   "source": [
    "69) In df, Compute the mean price of every fruit, while keeping the fruit as another column instead of an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a4c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eaa372",
   "metadata": {},
   "source": [
    "70) Join dataframes df1 and df2 by ‘fruit-pazham’ and ‘weight-kilo’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a250adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'kilo': ['high', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 6)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57adb8fe",
   "metadata": {},
   "source": [
    "71) Get the positions where the value of two columns match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43cc070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fruit1': np.random.choice(['apple', 'orange', 'banana'], 10),\n",
    "                    'fruit2': np.random.choice(['apple', 'orange', 'banana'], 10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da5c86",
   "metadata": {},
   "source": [
    "72) Create two new columns in df, one of which is a lag1 (shift column a down by 1 row) of column ‘a’ and the other is a lead1 (shift column b up by 1 row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e531adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))\n",
    "\n",
    "    a   b   c   d\n",
    "0  66  34  76  47\n",
    "1  20  86  10  81\n",
    "2  75  73  51  28\n",
    "3   1   1   9  83\n",
    "4  30  47  67   4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a01f7",
   "metadata": {},
   "source": [
    "73) Get the frequency of unique values in the entire dataframe df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b1df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d182d",
   "metadata": {},
   "source": [
    "74) Split the string column in df to form a dataframe with 3 columns as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\"STD, City    State\",\n",
    "\"33, Kolkata    West Bengal\",\n",
    "\"44, Chennai    Tamil Nadu\",\n",
    "\"40, Hyderabad    Telengana\",\n",
    "\"80, Bangalore    Karnataka\"], columns=['row'])\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a240a79a56f07427611ed7470762860540df2ed33899b99fe38f1fab4c51ff43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
